{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_FRIENDS_BERT_Trial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6b3007956d3b4ac98e7ec99054ed21b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_239d30a06364492796b31379fdc2844f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_69ba2bcd140a4d829ed0440552d9fe45","IPY_MODEL_95aac049d41547b6996250f72471c46e"]}},"239d30a06364492796b31379fdc2844f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69ba2bcd140a4d829ed0440552d9fe45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bdfc0749c5784233a4626a9163b05490","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81842af8dc13415cad61b3effbd365a0"}},"95aac049d41547b6996250f72471c46e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e0954f8f7d24bd08f46b6cd25a57da5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:01&lt;00:00, 712kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2bbf150d79bf428ab784080556b2a8f7"}},"bdfc0749c5784233a4626a9163b05490":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81842af8dc13415cad61b3effbd365a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e0954f8f7d24bd08f46b6cd25a57da5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2bbf150d79bf428ab784080556b2a8f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"_Mi-IFaf8d9z"},"source":["\r\n","# Pytorch를 활용한 미국드라마 프렌즈 대사 감정 분석 모델 \r\n","## 모델 : Bert Base\r\n","\r\n","## Dataset\r\n","EmotionLines 제공 프렌즈 대사 데이터셋<br>\r\n","\r\n","## 개발 환경\r\n","  - Google Corab (With GPU)<br>\r\n","  - 구글 드라이브 연동 후 본인 경로 설정 필수<br>\r\n","\r\n","### 본 자료는 Jangwon Park 님 제작 자료로써, <br>\r\n","### BERT 모델의 Accuracy 단순 참조용으로 첨부하였습니다."]},{"cell_type":"code","metadata":{"id":"mrR-4Z6p8f4p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58e18e1a-3102-4ed3-bb84-5f321fee88fe"},"source":["# Hugging Face의 트랜스포머 모델을 설치\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\r\u001b[K     |▏                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 27.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 19.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 22.9MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 26.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 28.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 29.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 27.2MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 24.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 23.1MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 23.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 23.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 23.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 23.1MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 23.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 23.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 23.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 23.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 23.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 45.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 45.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=37e5185ae480946096f8b7134843f8640141c85228ba154a611b3014da222ded\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ru7hzfn08pe6"},"source":["# 데이터 로드"]},{"cell_type":"code","metadata":{"id":"4eyuoZm-FubR"},"source":["!unzip Friends.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pFk-AHM9LHT"},"source":["# train data 전처리"]},{"cell_type":"code","metadata":{"id":"c6BxwDSF86KW"},"source":["import pandas as pd\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"liLCqtdO865-"},"source":["with open('friends_train.json', encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","train = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  train = train.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Jy6jDXp9E3K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f5f6a2b-86cf-4339-82e7-578d523312fc"},"source":["# 리뷰 문장 추출\n","train_sentences = train['utterance']\n","train_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    also I was the point person on my companys tr...\n","1                     You mustve had your hands full.\n","2                              That I did. That I did.\n","3        So lets talk a little bit about your duties.\n","4                               My duties?  All right.\n","5    Now youll be heading a whole division, so you...\n","6                                               I see.\n","7    But therell be perhaps 30 people under you so...\n","8                                        Good to know.\n","9                                We can go into detail\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"dDxy2m0T9WDK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4ce6a2e-f971-454b-adb3-edfe5f7100ed"},"source":["# Electra의 입력 형식에 맞게 변환\n","train_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in train_sentences]\n","train_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system. [SEP]',\n"," '[CLS] You must\\x92ve had your hands full. [SEP]',\n"," '[CLS] That I did. That I did. [SEP]',\n"," '[CLS] So let\\x92s talk a little bit about your duties. [SEP]',\n"," '[CLS] My duties?  All right. [SEP]',\n"," '[CLS] Now you\\x92ll be heading a whole division, so you\\x92ll have a lot of duties. [SEP]',\n"," '[CLS] I see. [SEP]',\n"," '[CLS] But there\\x92ll be perhaps 30 people under you so you can dump a certain amount on them. [SEP]',\n"," '[CLS] Good to know. [SEP]',\n"," '[CLS] We can go into detail [SEP]']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"s5goT6XKACZv","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"0e5bd290-d3d7-44a2-dfa1-a4e2c430daca"},"source":["# 감정을 숫자로 변환\n","def emotion_labeling(emotion):\n","   return{'anger' : 0,'disgust':1,'fear':2, 'joy':3,'neutral':4,'non-neutral':5,'sadness':6,'surprise':7}[emotion]\n","\n","emotion_labels = []\n","\n","for e in train['emotion']:\n","   emotion_labels.append(emotion_labeling(e))\n","\n","train['label'] = emotion_labels\n","train[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","      <th>emotion</th>\n","      <th>annotation</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Chandler</td>\n","      <td>also I was the point person on my companys tr...</td>\n","      <td>neutral</td>\n","      <td>4100000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Interviewer</td>\n","      <td>You mustve had your hands full.</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chandler</td>\n","      <td>That I did. That I did.</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The Interviewer</td>\n","      <td>So lets talk a little bit about your duties.</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chandler</td>\n","      <td>My duties?  All right.</td>\n","      <td>surprise</td>\n","      <td>2000030</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The Interviewer</td>\n","      <td>Now youll be heading a whole division, so you...</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Chandler</td>\n","      <td>I see.</td>\n","      <td>neutral</td>\n","      <td>3100010</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The Interviewer</td>\n","      <td>But therell be perhaps 30 people under you so...</td>\n","      <td>neutral</td>\n","      <td>4000100</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Chandler</td>\n","      <td>Good to know.</td>\n","      <td>neutral</td>\n","      <td>4100000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>The Interviewer</td>\n","      <td>We can go into detail</td>\n","      <td>neutral</td>\n","      <td>4000100</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           speaker  ... label\n","0         Chandler  ...     4\n","1  The Interviewer  ...     4\n","2         Chandler  ...     4\n","3  The Interviewer  ...     4\n","4         Chandler  ...     7\n","5  The Interviewer  ...     4\n","6         Chandler  ...     4\n","7  The Interviewer  ...     4\n","8         Chandler  ...     4\n","9  The Interviewer  ...     4\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"pdGutf98AIYm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f6e44a5-8abf-406b-aa79-4e00ae9eacbc"},"source":["# label 추출\n","train_labels = train['label'].values\n","train_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 4, 4, ..., 7, 4, 5])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Z_V1EzVgAMby","colab":{"base_uri":"https://localhost:8080/","height":125,"referenced_widgets":["6b3007956d3b4ac98e7ec99054ed21b5","239d30a06364492796b31379fdc2844f","69ba2bcd140a4d829ed0440552d9fe45","95aac049d41547b6996250f72471c46e","bdfc0749c5784233a4626a9163b05490","81842af8dc13415cad61b3effbd365a0","6e0954f8f7d24bd08f46b6cd25a57da5","2bbf150d79bf428ab784080556b2a8f7"]},"outputId":"89830e46-7441-4a0a-e242-a5fa40cabfcf"},"source":["from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import BertTokenizer,BertForSequenceClassification\n","import torch\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","train_tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n","\n","print (train_sentences[0])\n","print (train_tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b3007956d3b4ac98e7ec99054ed21b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[CLS] also I was the point person on my companys transition from the KL-5 to GR-6 system. [SEP]\n","['[CLS]', 'also', 'I', 'was', 'the', 'point', 'person', 'on', 'my', 'company', '##s', 'transition', 'from', 'the', 'K', '##L', '-', '5', 'to', 'GR', '-', '6', 'system', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iHxCfzHSBxzx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"233cdf2f-7e8b-4a35-a5b2-d68059c7cb94"},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","train_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in train_tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","train_input_ids[0]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  101, 10379,   146, 10134, 10105, 12331, 15042, 10135, 15127,\n","       12100, 10107, 35959, 10188, 10105,   148, 11369,   118,   126,\n","       10114, 58787,   118,   127, 11787,   119,   102,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"gcw7a4QnCZeV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4cca431-b17f-4663-8f44-128e030059d1"},"source":["# 어텐션 마스크 초기화\n","train_attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 ELECTRA 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in train_input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    train_attention_masks.append(seq_mask)\n","\n","print(train_attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tknBvYYcCiLe"},"source":["# pytorch 텐서로 변환\n","train_inputs = torch.tensor(train_input_ids)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_attention_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXTVwCIqEbxM"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXSEFgLjCjsf"},"source":["# 전처리- dev"]},{"cell_type":"code","metadata":{"id":"xG84K-CJCm2v"},"source":["with open('friends_dev.json', encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","dev = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  dev = dev.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgIymSLICrFI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60e8c552-4873-4a21-a3b4-2239fb46ba51"},"source":["# 리뷰 문장 추출\n","dev_sentences = dev['utterance']\n","dev_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Oh my God, hes lost it. Hes totally lost it.\n","1                                                What?\n","2    Or! Or, we could go to the bank, close our acc...\n","3                                     Youre a genius!\n","4              Aww, man, now we wont be bank buddies!\n","5                            Now, theres two reasons.\n","6                                                 Hey.\n","7                                                 Hey!\n","8    Ohh, you guys, remember that cute client I tol...\n","9                                              Where?!\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"LnpshdgjCsmi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59afb51d-5218-4730-bed9-703771d81f3f"},"source":["# Electra의 입력 형식에 맞게 변환\n","dev_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in dev_sentences]\n","dev_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] Oh my God, he\\x92s lost it. He\\x92s totally lost it. [SEP]',\n"," '[CLS] What? [SEP]',\n"," '[CLS] Or! Or, we could go to the bank, close our accounts and cut them off at the source. [SEP]',\n"," '[CLS] You\\x92re a genius! [SEP]',\n"," '[CLS] Aww, man, now we won\\x92t be bank buddies! [SEP]',\n"," '[CLS] Now, there\\x92s two reasons. [SEP]',\n"," '[CLS] Hey. [SEP]',\n"," '[CLS] Hey! [SEP]',\n"," '[CLS] Ohh, you guys, remember that cute client I told you about? I bit him. [SEP]',\n"," '[CLS] Where?! [SEP]']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"vo1casBICuuV","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"36be3534-e841-43d9-cc08-15393451ebf0"},"source":["# emotion으로 숫자로 변환\n","emotion_labels = []\n","\n","for e in dev['emotion']:\n","   emotion_labels.append(emotion_labeling(e))\n","\n","dev['label'] = emotion_labels\n","dev[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","      <th>emotion</th>\n","      <th>annotation</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Phoebe</td>\n","      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n","      <td>non-neutral</td>\n","      <td>0002120</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Monica</td>\n","      <td>What?</td>\n","      <td>surprise</td>\n","      <td>1000130</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ross</td>\n","      <td>Or! Or, we could go to the bank, close our acc...</td>\n","      <td>neutral</td>\n","      <td>3000200</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chandler</td>\n","      <td>Youre a genius!</td>\n","      <td>joy</td>\n","      <td>0500000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Joey</td>\n","      <td>Aww, man, now we wont be bank buddies!</td>\n","      <td>sadness</td>\n","      <td>0040100</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Chandler</td>\n","      <td>Now, theres two reasons.</td>\n","      <td>neutral</td>\n","      <td>4000010</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Phoebe</td>\n","      <td>Hey.</td>\n","      <td>neutral</td>\n","      <td>3100010</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>All</td>\n","      <td>Hey!</td>\n","      <td>joy</td>\n","      <td>1300010</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Phoebe</td>\n","      <td>Ohh, you guys, remember that cute client I tol...</td>\n","      <td>neutral</td>\n","      <td>4100000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Rachel</td>\n","      <td>Where?!</td>\n","      <td>surprise</td>\n","      <td>0000050</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    speaker  ... label\n","0    Phoebe  ...     5\n","1    Monica  ...     7\n","2      Ross  ...     4\n","3  Chandler  ...     3\n","4      Joey  ...     6\n","5  Chandler  ...     4\n","6    Phoebe  ...     4\n","7       All  ...     3\n","8    Phoebe  ...     4\n","9    Rachel  ...     7\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"JJSFDshJCw01","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a042a3a-7c0e-4fe8-971a-748c16f898e1"},"source":["# 라벨 추출\n","dev_labels = dev['label'].values\n","dev_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 7, 4, ..., 6, 6, 6])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"Ptr8LXfBCy-w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d870f3a-df30-4f63-d0fa-7d5431ed75c0"},"source":["tokenizer =BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","dev_tokenized_texts = [tokenizer.tokenize(sent) for sent in dev_sentences]\n","\n","print (dev_sentences[0])\n","print (dev_tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] Oh my God, hes lost it. Hes totally lost it. [SEP]\n","['[CLS]', 'Oh', 'my', 'God', ',', 'he', '##s', 'lost', 'it', '.', 'He', '##s', 'totally', 'lost', 'it', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WTL0iovBDK9e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f22c3bc8-8337-4b81-bdd3-7368c10b5d73"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","dev_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in dev_tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","dev_input_ids = pad_sequences(dev_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","dev_input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,  22800,  15127,  14015,    117,  10261,  10107,  14172,\n","        10271,    119,  10357,  10107, 110240,  14172,  10271,    119,\n","          102,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"FmyVPo9xDwm3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d7986d6-6f80-4ca8-c134-009eae836830"},"source":["# 어텐션 마스크 초기화\n","dev_attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 Electra 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in dev_input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    dev_attention_masks.append(seq_mask)\n","\n","print(dev_attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XHvOgXoeDyNp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2f7c5f6-fa66-4a03-e64a-2ca315673ae9"},"source":["# 데이터를 파이토치의 텐서로 변환\n","\n","validation_inputs = torch.tensor(dev_input_ids)\n","validation_labels = torch.tensor(dev_labels)\n","validation_masks = torch.tensor(dev_attention_masks)\t\t\t\t\n","\n","\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])\n","\t\t\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([   101,  22800,  15127,  14015,    117,  10261,  10107,  14172,  10271,\n","           119,  10357,  10107, 110240,  14172,  10271,    119,    102,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(5)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9krBeyteE0gz"},"source":["validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xaWxpdzkE_B-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJs8B9QIFApJ"},"source":["# 전처리 - test set"]},{"cell_type":"code","metadata":{"id":"PwZFIWGQFDPB"},"source":["with open('friends_test.json', encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","test = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  test = test.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKdBy_WHFE-O","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"3cde0102-c1f1-46f4-ba32-cf00c12a5f78"},"source":["emotion_labels = []\n","\n","for e in test['emotion']:\n","   emotion_labels.append(emotion_labeling(e))\n","\n","test['label'] = emotion_labels\n","test[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","      <th>emotion</th>\n","      <th>annotation</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mark</td>\n","      <td>Why do all youre coffee mugs have numbers on ...</td>\n","      <td>surprise</td>\n","      <td>2000030</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rachel</td>\n","      <td>Oh. Thats so Monica can keep track. That way ...</td>\n","      <td>non-neutral</td>\n","      <td>2100011</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Rachel</td>\n","      <td>Y'know what?</td>\n","      <td>neutral</td>\n","      <td>3000020</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ross</td>\n","      <td>It didnt.</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Frank</td>\n","      <td>Okay, so what you used to have with Rachel, is...</td>\n","      <td>joy</td>\n","      <td>1300010</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Joey</td>\n","      <td>Now, wh-what, what is that like?</td>\n","      <td>surprise</td>\n","      <td>1000040</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Frank</td>\n","      <td>Its so cool man, its so, its just cause be...</td>\n","      <td>joy</td>\n","      <td>2300000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Ross</td>\n","      <td>Yeah, yeah.</td>\n","      <td>neutral</td>\n","      <td>5000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Joey</td>\n","      <td>Why cant I find that?</td>\n","      <td>non-neutral</td>\n","      <td>0020021</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Ross</td>\n","      <td>Dont ask me, I had it and I blew it!</td>\n","      <td>anger</td>\n","      <td>0000302</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  speaker                                          utterance  ... annotation label\n","0    Mark  Why do all youre coffee mugs have numbers on ...  ...    2000030     7\n","1  Rachel  Oh. Thats so Monica can keep track. That way ...  ...    2100011     5\n","2  Rachel                                       Y'know what?  ...    3000020     4\n","3    Ross                                         It didnt.  ...    5000000     4\n","4   Frank  Okay, so what you used to have with Rachel, is...  ...    1300010     3\n","5    Joey                   Now, wh-what, what is that like?  ...    1000040     7\n","6   Frank  Its so cool man, its so, its just cause be...  ...    2300000     3\n","7    Ross                                        Yeah, yeah.  ...    5000000     4\n","8    Joey                             Why cant I find that?  ...    0020021     5\n","9    Ross              Dont ask me, I had it and I blew it!  ...    0000302     0\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"XIdsESLZFGnS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"305b2705-47e2-4b73-997e-e74bc4206bf8"},"source":["# 리뷰 문장 추출\n","sentences = test['utterance']\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Why do all youre coffee mugs have numbers on ...\n","1    Oh. Thats so Monica can keep track. That way ...\n","2                                         Y'know what?\n","3                                           It didnt.\n","4    Okay, so what you used to have with Rachel, is...\n","5                     Now, wh-what, what is that like?\n","6    Its so cool man, its so, its just cause be...\n","7                                          Yeah, yeah.\n","8                               Why cant I find that?\n","9                Dont ask me, I had it and I blew it!\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"DyhbgJA3FIF5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c12adb5f-8852-4406-b73c-9917945e2159"},"source":["# ELECTRA의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] Why do all you\\x92re coffee mugs have numbers on the bottom? [SEP]',\n"," '[CLS] Oh. That\\x92s so Monica can keep track. That way if one on them is missing, she can be like, \\x91Where\\x92s number 27?!\\x92 [SEP]',\n"," \"[CLS] Y'know what? [SEP]\",\n"," '[CLS] It didn\\x92t. [SEP]',\n"," '[CLS] Okay, so what you used to have with Rachel, is what I\\x92ve got with Alice. [SEP]',\n"," '[CLS] Now, wh-what, what is that like? [SEP]',\n"," '[CLS] It\\x92s so cool man, it\\x92s so, it\\x92s just \\x91cause being with her is so much better than like not being with her. [SEP]',\n"," '[CLS] Yeah, yeah. [SEP]',\n"," '[CLS] Why can\\x92t I find that? [SEP]',\n"," '[CLS] Don\\x92t ask me, I had it and I blew it! [SEP]']"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"hj9Xpg1dFLAY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0e29aba-5c6b-411c-aaed-2768cbd1b360"},"source":["# 라벨 추출\n","labels = test['label'].values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7, 5, 4, ..., 4, 4, 4])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"xHnw3m1_FMYZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfe92803-b64a-4008-cd4a-53018ee6766a"},"source":["tokenizer =BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print (sentences[0])\n","print (tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] Why do all youre coffee mugs have numbers on the bottom? [SEP]\n","['[CLS]', 'Why', 'do', 'all', 'your', '##e', 'coffee', 'mu', '##gs', 'have', 'numbers', 'on', 'the', 'bottom', '?', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sSW26HQUFWJt"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 100\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3C7E1ey_FXhm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc783510-d40e-4327-f836-ddc7dc347758"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LYwKjhR2FZCO"},"source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6tfGct4FaxE"},"source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMSjArqgFdGS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQ8JfAZ6Fh1Z"},"source":["# 모델 생성"]},{"cell_type":"code","metadata":{"id":"_w6FefwvIYDR"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BR11MqeFi91","colab":{"base_uri":"https://localhost:8080/"},"outputId":"017fda49-c105-46d1-f1b8-fc1cfd094312"},"source":["# GPU 디바이스 이름 구함\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 디바이스 이름 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XVlooU4DFkEe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"887d2990-d156-4626-e7f0-ec1320901b7f"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EhIWpXlyFlaO"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=8)\n","model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvHHc6XoFyw_"},"source":["from transformers import get_linear_schedule_with_warmup,AdamW\n","\n","# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 4\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mItHTct_F1g-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608619989999,"user_tz":-540,"elapsed":1197,"user":{"displayName":"손무수","photoUrl":"","userId":"06356770852246195014"}},"outputId":"53b1f31b-042c-420d-f120-8e4e6d877864"},"source":["2e-5"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2e-05"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"lcyMrx29GEYE"},"source":["# 모델 학습"]},{"cell_type":"code","metadata":{"id":"nXwwxpPTGbbq"},"source":["import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUlPCQ9ZGFlk"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-gFoRGoGHKM"},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-Nms45dewyS"},"source":["# f1-score parameter\n","from sklearn.metrics import f1_score\n","f1_score_avg = []\n","trues = []\n","preds = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcwnofpgGNEj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"794dde88-7f74-4aa1-96a4-8c3a7bd07a99"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","\n","        \n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        #\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        trues_flat = label_ids.flatten()\n","        trues.extend(trues_flat)\n","        preds.extend(pred_flat)\n","\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(trues[:10])\n","    print(preds[:10])\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  f1 score macro: {0: 2f}\".format(f1_score(y_true=trues,y_pred= preds, labels = [0,1,2,3,4,5,6,7], average='macro')))\n","    print(\"  f1 score micro: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='micro')))\n","    print(\"  f1 score weighted: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='weighted')))\n","    print(f\"  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\")\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","\n","  Average training loss: 1.33\n","  Training epcoh took: 0:04:34\n","\n","Running Validation...\n","[5, 7, 4, 3, 6, 4, 4, 3, 4, 7]\n","[7, 7, 5, 3, 5, 4, 4, 3, 5, 7]\n","  Accuracy: 0.54\n","  f1 score macro:  0.282532\n","  f1 score micro:  0.544992\n","  f1 score weighted:  0.487760\n","  f1 score none: [0.08080808 0.         0.         0.50154799 0.73967684 0.22941176\n"," 0.14925373 0.55955679]\n","  Validation took: 0:00:10\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","\n","  Average training loss: 1.14\n","  Training epcoh took: 0:04:38\n","\n","Running Validation...\n","[5, 7, 4, 3, 6, 4, 4, 3, 4, 7]\n","[7, 7, 5, 3, 5, 4, 4, 3, 5, 7]\n","  Accuracy: 0.56\n","  f1 score macro:  0.301831\n","  f1 score micro:  0.550934\n","  f1 score weighted:  0.501771\n","  f1 score none: [0.13592233 0.         0.         0.51960784 0.7438091  0.24423338\n"," 0.20547945 0.56559767]\n","  Validation took: 0:00:10\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","\n","  Average training loss: 1.01\n","  Training epcoh took: 0:04:38\n","\n","Running Validation...\n","[5, 7, 4, 3, 6, 4, 4, 3, 4, 7]\n","[7, 7, 5, 3, 5, 4, 4, 3, 5, 7]\n","  Accuracy: 0.57\n","  f1 score macro:  0.311163\n","  f1 score micro:  0.556593\n","  f1 score weighted:  0.509688\n","  f1 score none: [0.16403785 0.         0.         0.53257143 0.74911243 0.25043478\n"," 0.22707424 0.566077  ]\n","  Validation took: 0:00:10\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","\n","  Average training loss: 0.90\n","  Training epcoh took: 0:04:38\n","\n","Running Validation...\n","[5, 7, 4, 3, 6, 4, 4, 3, 4, 7]\n","[7, 7, 5, 3, 5, 4, 4, 3, 5, 7]\n","  Accuracy: 0.56\n","  f1 score macro:  0.317977\n","  f1 score micro:  0.556876\n","  f1 score weighted:  0.514553\n","  f1 score none: [0.19954649 0.         0.         0.53819444 0.74870874 0.25679949\n"," 0.23003195 0.57053292]\n","  Validation took: 0:00:10\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TihX1ZnzGR6D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hYAU0odGT8C"},"source":["# 테스트셋 평가"]},{"cell_type":"code","metadata":{"id":"49nGvOCiGVcw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2m13eWCYQurk","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"a0a61617-254f-4a78-fb4f-5aea49e468f0"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","   #\n","    pred_flat = np.argmax(logits, axis=1).flatten()\n","    trues_flat = label_ids.flatten()\n","    trues.extend(trues_flat)\n","    preds.extend(pred_flat)\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"  f1 score macro: {0: 2f}\".format(f1_score(y_true=trues,y_pred= preds, labels = [0,1,2,3,4,5,6,7], average='macro')))\n","print(\"  f1 score micro: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='micro')))\n","print(\"  f1 score weighted: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='weighted')))\n","print(f\"  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\")\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Accuracy: 0.60\n","  f1 score macro:  0.340905\n","  f1 score micro:  0.576378\n","  f1 score weighted:  0.546143\n","  f1 score none: [0.23931624 0.         0.         0.57464455 0.7634105  0.30752454\n"," 0.27916667 0.5631769 ]\n","Test took: 0:00:22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ek1SQ9Fz5Ccu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90f43rbcSVOe"},"source":["# 새로운 문장 테스트"]},{"cell_type":"code","metadata":{"id":"9NMhJcUaSXGi"},"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhVUEXqgSaL6"},"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYBc8mgSSbl-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bfc32f6-6e5e-48d2-ff2c-166bb2dd2f8c"},"source":["logits = test_sentences(['Nice job.'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.869198   -0.95660347 -0.97209674  0.214642    3.1684265   1.7565498\n","  -0.58515584 -1.5049354 ]]\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z7E7QhoGSfOr","colab":{"base_uri":"https://localhost:8080/","height":176},"outputId":"41d0bbc3-b130-4088-f14f-75e27a0de1a5"},"source":["torch.save(model,)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-a4779374805d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: save() missing 1 required positional argument: 'f'"]}]}]}